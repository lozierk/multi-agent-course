{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hamzafarooq/multi-agent-course/blob/main/Module_3_Agentic_RAG/Semantic_Cache/Semantic_cache_from_scratch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "p2KzXaJYks8S",
      "metadata": {
        "id": "p2KzXaJYks8S"
      },
      "source": [
        "**If you use our code, please cite:**\n",
        "\n",
        "@misc{2024<br>\n",
        "  title = {Semantic Cache from Scratch},<br>\n",
        "  author = {Hamza Farooq, Darshil Modi, Kanwal Mehreen, Nazila Shafiei},<br>\n",
        "  keywords = {Semantic Cache},<br>\n",
        "  year = {2024},<br>\n",
        "  copyright = {APACHE 2.0 license}<br>\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "gxQxLQJymkCl",
      "metadata": {
        "id": "gxQxLQJymkCl"
      },
      "source": [
        "## Semantic Cache\n",
        "\n",
        "Semantic caching accelerates retrieval-augmented workflows by storing and reusing previous embedding-based lookups instead of issuing fresh queries every time. In this notebook, we'll build a lightweight semantic cache from scratch using:\n",
        "\n",
        "- **Nomic text embeddings** (`nomic-ai/nomic-embed-text-v1.5`) to convert documents and queries into dense vectors  \n",
        "- **FAISS** (Facebook AI Similarity Search) to index and quickly search those vectors  \n",
        "- **Traversaal Pro API** to perform RAG over the AWS documentation corpus when a cache miss occurs  \n",
        "\n",
        "Rather than re-computing embeddings and retrieval for every query, our cache lets us:\n",
        "\n",
        "1. **Embed** each new query and check if it's already \"covered\" by a cached result  \n",
        "2. **Fall back** to a full RAG retrieval (and store the new result) only when necessary  \n",
        "3. **Skip the cache entirely** for time-sensitive questions that need a fresh answer  \n",
        "4. **Invoke** the Traversaal Pro API for document-grounded answers on cache misses  \n",
        "\n",
        "This approach reduces redundant compute, lowers end-to-end latency, and makes RAG pipelines more efficient‚Äîespecially when query patterns exhibit repetition or high similarity. We'll walk through:\n",
        "\n",
        "1. Loading the Nomic embed model with `trust_remote_code=True`  \n",
        "2. Building a FAISS index for fast L2 nearest-neighbor lookup  \n",
        "3. Implementing the core cache hit/miss logic with a time-sensitivity filter  \n",
        "4. Falling back to Traversaal Pro RAG API for live document retrieval on cache misses  \n",
        "5. Measuring performance gains against a \"no-cache\" baseline  \n",
        "\n",
        "By the end, you'll have a reusable semantic cache scaffold that you can plug into any RAG or search-over-embeddings pipeline. Let's get started!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Hm2NYbYQmykl",
      "metadata": {
        "id": "Hm2NYbYQmykl"
      },
      "source": [
        "## Setup and Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "025_hZMnZUIE",
      "metadata": {
        "id": "025_hZMnZUIE",
        "outputId": "8b62947f-d36f-426f-aac8-9c08e8ee9fda",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.12/dist-packages (1.13.2)\n",
            "Requirement already satisfied: sentence_transformers in /usr/local/lib/python3.12/dist-packages (5.2.3)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (5.2.0)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.12/dist-packages (1.2.1)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.12/dist-packages (0.8.2)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.12/dist-packages (from faiss-cpu) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from faiss-cpu) (26.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from sentence_transformers) (1.4.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from sentence_transformers) (2.10.0+cpu)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from sentence_transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence_transformers) (1.16.3)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.12/dist-packages (from sentence_transformers) (4.15.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from sentence_transformers) (4.67.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2025.11.3)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.2)\n",
            "Requirement already satisfied: typer-slim in /usr/local/lib/python3.12/dist-packages (from transformers) (0.24.0)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.7.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (3.24.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (2025.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (1.2.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (0.28.1)\n",
            "Requirement already satisfied: shellingham in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (1.5.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence_transformers) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence_transformers) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence_transformers) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence_transformers) (3.1.6)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence_transformers) (1.5.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence_transformers) (3.6.0)\n",
            "Requirement already satisfied: typer>=0.24.0 in /usr/local/lib/python3.12/dist-packages (from typer-slim->transformers) (0.24.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface-hub>=0.20.0->sentence_transformers) (4.12.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface-hub>=0.20.0->sentence_transformers) (2026.1.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface-hub>=0.20.0->sentence_transformers) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface-hub>=0.20.0->sentence_transformers) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->huggingface-hub>=0.20.0->sentence_transformers) (0.16.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.11.0->sentence_transformers) (1.3.0)\n",
            "Requirement already satisfied: click>=8.2.1 in /usr/local/lib/python3.12/dist-packages (from typer>=0.24.0->typer-slim->transformers) (8.3.1)\n",
            "Requirement already satisfied: rich>=12.3.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.24.0->typer-slim->transformers) (13.9.4)\n",
            "Requirement already satisfied: annotated-doc>=0.0.2 in /usr/local/lib/python3.12/dist-packages (from typer>=0.24.0->typer-slim->transformers) (0.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.11.0->sentence_transformers) (3.0.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=12.3.0->typer>=0.24.0->typer-slim->transformers) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=12.3.0->typer>=0.24.0->typer-slim->transformers) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=12.3.0->typer>=0.24.0->typer-slim->transformers) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "# Install the necessary libraries\n",
        "!pip install -U faiss-cpu sentence_transformers transformers python-dotenv einops"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "52273bc0-575b-4007-b63d-bfe53d4abde6",
      "metadata": {
        "id": "52273bc0-575b-4007-b63d-bfe53d4abde6"
      },
      "outputs": [],
      "source": [
        "# Import the necessary libraries\n",
        "\n",
        "# FAISS for efficient similarity search over vector embeddings\n",
        "import faiss  # Builds and queries approximate nearest neighbor indices\n",
        "\n",
        "# Lightweight SQL database for caching metadata, query logs, or evaluation results\n",
        "import sqlite3  # Persistence layer for storing cache entries or metrics\n",
        "\n",
        "# SentenceTransformers wrapper around transformer models for text embeddings\n",
        "from sentence_transformers import SentenceTransformer  # Loads Nomic/embed or other SBERT-style models\n",
        "\n",
        "# PyTorch backend required by SentenceTransformer and optional model fine-tuning\n",
        "import torch  # Tensor operations, GPU acceleration, and model inference support\n",
        "\n",
        "# Transformers library components for causal LLM-based answer generation\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "#   - AutoModelForCausalLM: Load pretrained language models (e.g., GPT variants)\n",
        "#   - AutoTokenizer: Tokenize text input/output for the LLM\n",
        "\n",
        "# Core numerical library for array and matrix operations on embeddings\n",
        "import numpy as np  # Handles vector math, concatenation, and statistical computations\n",
        "\n",
        "# Pretty-printing complex Python objects during development/debugging\n",
        "from pprint import pprint  # Nicely formats nested dicts or lists when exploring outputs"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4JHRRiuKlM3t",
      "metadata": {
        "id": "4JHRRiuKlM3t"
      },
      "source": [
        "# Define the Retrieval Functions\n",
        "\n",
        "This notebook uses **two different APIs** depending on whether a question is stable or time-sensitive:\n",
        "\n",
        "| Question type | Backend | Cached? |\n",
        "|---|---|---|\n",
        "| Stable / document-grounded | **Traversaal Pro** (RAG over AWS guidebook) | ‚úÖ Yes |\n",
        "| Time-sensitive / live data | **SerpApi** (Google search results) | ‚ùå Never |\n",
        "\n",
        "---\n",
        "\n",
        "## Traversaal Pro ‚Äî RAG as a Service\n",
        "\n",
        "[Traversaal Pro](https://pro.traversaal.ai) is a hosted RAG platform. You upload documents into a project; the API handles chunking, embedding, retrieval, and generation. In this notebook the corpus is the **AWS Guidebook**.\n",
        "\n",
        "**API details:**\n",
        "\n",
        "| Property | Value |\n",
        "|---|---|\n",
        "| Endpoint | `POST https://pro-documents.traversaal-api.com/documents/search` |\n",
        "| Auth | `Authorization: Bearer <your_token>` |\n",
        "| Request | `{\"query\": \"...\", \"generation\": true}` |\n",
        "| Response | `{\"response\": \"...\", \"references\": [{score, chunk_text, ...}]}` |\n",
        "\n",
        "Sign up at [pro.traversaal.ai](https://pro.traversaal.ai) to get your Bearer token.\n",
        "\n",
        "---\n",
        "\n",
        "## SerpApi ‚Äî Live Internet Search\n",
        "\n",
        "[SerpApi](https://serpapi.com) provides structured Google search results via a REST API. We use it for time-sensitive questions that require up-to-date information from the web (current events, live pricing, outages, etc.) ‚Äî answers that must never be served from cache.\n",
        "\n",
        "**API details:**\n",
        "\n",
        "| Property | Value |\n",
        "|---|---|\n",
        "| Endpoint | `GET https://serpapi.com/search.json` |\n",
        "| Auth | `?api_key=<your_key>` query param |\n",
        "| Key params | `q=<query>`, `engine=google`, `num=5` |\n",
        "| Response | `organic_results[].snippet`, `answer_box` |\n",
        "\n",
        "Sign up at [serpapi.com](https://serpapi.com) for a free API key (100 searches/month on the free tier)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "38331891-adb4-4d16-b26f-d74d7c9ce728",
      "metadata": {
        "id": "38331891-adb4-4d16-b26f-d74d7c9ce728",
        "outputId": "6fc8f9b3-e20b-4b3a-99f2-acacd62595cb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running on Colab ‚Äî credentials loaded from Secrets.\n",
            "Traversaal Pro key loaded: ‚úÖ\n",
            "SerpApi key loaded:        ‚úÖ\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import requests  # HTTP client for REST API calls\n",
        "\n",
        "# ‚îÄ‚îÄ Credential loading ‚Äî works on Colab and locally ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "# On Colab:  store keys in the Secrets panel (üîë left sidebar)\n",
        "#              TRAVERSAAL_PRO_API_KEY\n",
        "#              SERP_API_KEY\n",
        "# Locally:   keys are read from Module_3_Agentic_RAG/.env\n",
        "#              traversaal_pro_api_key=<token>\n",
        "#              serp_api_key=<key>\n",
        "\n",
        "try:\n",
        "    from google.colab import userdata\n",
        "    traversaal_pro_api_key = userdata.get(\"traversaal_pro_api_key\")\n",
        "    serp_api_key = userdata.get(\"SERP_API_KEY\")\n",
        "    print(\"Running on Colab ‚Äî credentials loaded from Secrets.\")\n",
        "except ImportError:\n",
        "    from dotenv import load_dotenv, find_dotenv\n",
        "    load_dotenv(find_dotenv())   # walks up the directory tree to find .env\n",
        "    # .env uses lowercase key names; fall back to uppercase too\n",
        "    traversaal_pro_api_key = os.getenv(\"traversaal_pro_api_key\") or os.getenv(\"TRAVERSAAL_PRO_API_KEY\")\n",
        "    serp_api_key = os.getenv(\"serp_api_key\") or os.getenv(\"SERP_API_KEY\")\n",
        "    print(\"Running locally ‚Äî credentials loaded from .env file.\")\n",
        "\n",
        "print(f\"Traversaal Pro key loaded: {'‚úÖ' if traversaal_pro_api_key else '‚ùå MISSING'}\")\n",
        "print(f\"SerpApi key loaded:        {'‚úÖ' if serp_api_key else '‚ùå MISSING'}\")\n",
        "\n",
        "\n",
        "# ‚îÄ‚îÄ Traversaal Pro: RAG over AWS Guidebook ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "\n",
        "def make_prediction(query: str) -> dict:\n",
        "    \"\"\"\n",
        "    Query the Traversaal Pro RAG API with a natural language question.\n",
        "\n",
        "    The API performs retrieval over the configured document corpus (AWS Guidebook)\n",
        "    and returns a generated answer together with source chunk references.\n",
        "\n",
        "    Request:\n",
        "        POST https://pro-documents.traversaal-api.com/documents/search\n",
        "        {\"query\": \"...\", \"generation\": true}\n",
        "\n",
        "    Response:\n",
        "        {\n",
        "          \"response\": \"<generated answer string>\",\n",
        "          \"references\": [\n",
        "            {\n",
        "              \"score\": 0.81,\n",
        "              \"file_id\": \"...\",\n",
        "              \"chunk_index\": 1,\n",
        "              \"chunk_text\": \"...\",\n",
        "              \"original_file_name\": \"aws-guide.pdf\"\n",
        "            },\n",
        "            ...\n",
        "          ]\n",
        "        }\n",
        "\n",
        "    Args:\n",
        "        query (str): Natural language question answerable from the AWS Guidebook.\n",
        "\n",
        "    Returns:\n",
        "        dict: Full API response with 'response' and 'references' keys.\n",
        "    \"\"\"\n",
        "    if not traversaal_pro_api_key:\n",
        "        raise RuntimeError(\"Missing TRAVERSAAL_PRO_API_KEY ‚Äî add it to Colab Secrets or .env\")\n",
        "\n",
        "    url = \"https://pro-documents.traversaal-api.com/documents/search\"\n",
        "    headers = {\n",
        "        \"Authorization\": f\"Bearer {traversaal_pro_api_key}\",\n",
        "        \"Content-Type\": \"application/json\",\n",
        "    }\n",
        "    payload = {\"query\": query, \"generation\": True}\n",
        "\n",
        "    try:\n",
        "        response = requests.post(url, json=payload, headers=headers)\n",
        "        if response.status_code == 200:\n",
        "            print(\"Traversaal Pro: request successful.\")\n",
        "            try:\n",
        "                return response.json()\n",
        "            except ValueError:\n",
        "                print(\"Response was not valid JSON.\")\n",
        "                return None\n",
        "        else:\n",
        "            print(f\"Traversaal Pro: request failed ({response.status_code}): {response.text}\")\n",
        "            return None\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Traversaal Pro: request error: {e}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "# ‚îÄ‚îÄ SerpApi: Live Google Search ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "\n",
        "def search_live(query: str) -> str:\n",
        "    \"\"\"\n",
        "    Search Google in real time using SerpApi and return a formatted answer.\n",
        "\n",
        "    Used exclusively for time-sensitive questions (current events, live pricing,\n",
        "    outages, etc.) where a cached answer would quickly become stale.\n",
        "    Results are intentionally NOT stored in the semantic cache.\n",
        "\n",
        "    Args:\n",
        "        query (str): The time-sensitive question to search for.\n",
        "\n",
        "    Returns:\n",
        "        str: A formatted string combining the answer box (if present) and\n",
        "             top organic result snippets.\n",
        "    \"\"\"\n",
        "    if not serp_api_key:\n",
        "        raise RuntimeError(\"Missing SERP_API_KEY ‚Äî add it to Colab Secrets or .env\")\n",
        "\n",
        "    print(\"SerpApi: fetching live search results üåê ...\")\n",
        "    params = {\n",
        "        \"q\": query,\n",
        "        \"api_key\": serp_api_key,\n",
        "        \"engine\": \"google\",\n",
        "        \"num\": 5,\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        response = requests.get(\"https://serpapi.com/search.json\", params=params)\n",
        "        response.raise_for_status()\n",
        "        data = response.json()\n",
        "\n",
        "        parts = []\n",
        "\n",
        "        # Answer box ‚Äî Google's highlighted direct answer (most relevant)\n",
        "        answer_box = data.get(\"answer_box\", {})\n",
        "        if answer_box.get(\"answer\"):\n",
        "            parts.append(f\"[Direct Answer] {answer_box['answer']}\")\n",
        "        elif answer_box.get(\"snippet\"):\n",
        "            parts.append(f\"[Direct Answer] {answer_box['snippet']}\")\n",
        "\n",
        "        # Top organic results ‚Äî titles + snippets\n",
        "        for i, result in enumerate(data.get(\"organic_results\", [])[:5], start=1):\n",
        "            title = result.get(\"title\", \"\")\n",
        "            snippet = result.get(\"snippet\", \"\")\n",
        "            link = result.get(\"link\", \"\")\n",
        "            if snippet:\n",
        "                parts.append(f\"[{i}] {title}\\n    {snippet}\\n    Source: {link}\")\n",
        "\n",
        "        if not parts:\n",
        "            return \"No results found.\"\n",
        "\n",
        "        return \"\\n\\n\".join(parts)\n",
        "\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        return f\"SerpApi request error: {e}\"\n",
        "    except Exception as e:\n",
        "        return f\"Unexpected error: {e}\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -X POST https://pro-documents.traversaal-api.com/documents/search \\\n",
        "    -H \"Authorization: Bearer eyJhbGciOiJSUzI1NiIsInR5cCI6IkpXVCJ9.eyJzdWIiOiJnb29nbGUtb2F1dGgyfDEwNDA5ODYzMjA2ODY5MjY4NjE4OSIsImlhdCI6MTc3MTYyNzgzNywidXNlcklkIjoiZ29vZ2xlLW9hdXRoMnwxMDQwOTg2MzIwNjg2OTI2ODYxODkiLCJwcm9qZWN0SWRzIjpbImNtaWZoNjkyNDAwMDE1eHF2ejFtdDNrNTMiXSwib3JnYW5pc2F0aW9uSWQiOiJvcmdfMm53VFNNNVYxWHhrRnBZZE9vaEFONGU1NDl5In0.OMR48WD_KxTK333tl7beDEB6Tkj4VO2aIyfj6qBxsoreK-NWBEf-K5eALy_odcf6yzuubtodvqCVK_qNW7yjZ7exssIbxvCHqByxVpUln8eNBS1B17E84JYbG2xnMAD56UeDWjRzVYtOrIfKAFR61gm5n8Tqo0WcELAxa_PgFo25EaTGm2RAWMhkLi03hU-znOMWvUWNWXmA35PhbzQ8Wzzj0qcllKflcBJYRwTlhfT1-I5CJOgLB1UoIWQ5oQpBiR9kPmBauR8fOa54I564yTgA21ZwaiCN0SB0laGB4ialH1bVgdEqBBoIf0GVKWhY8N7CX1WROu7-6Pnz6lFKFg\" \\\n",
        "    -H \"Content-Type: application/json\" \\\n",
        "    -d '{\"query\":\"What is s3 bucket on AWS?\", \"generation\":true}'"
      ],
      "metadata": {
        "id": "EWmgtS4zbeXo",
        "outputId": "64432509-9dad-4eab-8cf6-3417c179a03b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "EWmgtS4zbeXo",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"response\":\"An S3 bucket on AWS is a storage container used in Amazon Simple Storage Service (S3) to hold and organize objects (files). It is conceptually similar to a folder in a traditional file-storage system. Before you can store data in S3, you need to create a bucket. Each bucket has a globally unique name across all AWS accounts, and objects are stored within these buckets using unique keys to identify them. Access control and billing are also managed at the bucket level [1].\",\"references\":[{\"score\":0.80882984,\"file_id\":\"file_94bf098ddc80e7ca\",\"chunk_index\":1,\"chunk_text\":\"Amazon Simple Storage Service (S3)\\nWhat is it?\\nAmazon Simple Storage Service, commonly known as S3, is a fast, scalable, and durable\\nobject-storage service. S3 can be used to store and retrieve any type and any amount of data.\\nHow does it work?\\nAt its core, S3 is an object-storage service. which is diÔ¨Äerent from the traditional Ô¨Åle-storage\\nservice. Data in S3 is stored as objects. Each object contains a unique identiÔ¨Åer, some\\nmetadata about the object and the data itself.\\nKey Concepts\\nBuckets\\nAn S3 bucket is conceptually similar to a folder in a Ô¨Åle-storage system. Objects in S3 are\\nstored within a bucket. An S3 bucket needs to be created before data can be stored in S3.\\nFor e.g. if there is an object with the key omgcat.png in the S3 bucket adorable-cat-\\nphotos, \\nthen \\nthe \\naddressable \\npath \\nof \\nthe \\nobject \\nis \\ns3://adorable-cat-\\nphotos/omgcat.png.\\nBuckets are important to understand for some of the following reasons:\\nS3 bucket names are globally unique across all AWS accounts. For e.g. if a bucket with the\\nname adorable-cat-photos already exists, nobody else will be able to create a bucket\\nwith this name.\\nAccess Control can be implemented at bucket level\\nAWS billing is based on aggregate bucket sizes\\nObject keys\\nTo create an object in S3, a key must be speciÔ¨Åed. This key uniquely identiÔ¨Åes an object\\nwithin a bucket. Since S3 is an object-storage service with a Ô¨Çat namespace (no hierarchy), it\\nhas no concept of folders.\\nThe following are all valid keys for an object:\\nomgcatphoto.png \\ncatvideos/omgwhatacat.mp4 \\nphotos/2020/11/11/photo-of-the-day.png \\nObject Metadata\\nThere are two kinds of metadata associated with an object: system metadata and user-\\ndeÔ¨Åned metadata. User-deÔ¨Åned metadata can be added when an object is created or\\nupdated.\\nSome examples of system metadata are:\\nObject creation date\",\"original_file_name\":\"aws-guide (1).pdf\"},{\"score\":0.68136007,\"file_id\":\"file_94bf098ddc80e7ca\",\"chunk_index\":3,\"chunk_text\":\"Creating a bucket\\nCLI\\naws s3 mb s3://bucket-name\\nPython (boto3)\\ns3_client = boto3.client('s3') \\ns3_client.create_bucket(Bucket=bucket_name) \\nList buckets and objects\\nCLI\\n# List all buckets \\naws s3 ls \\n \\n# List objects within bucket \\naws s3 ls s3://bucket-name\\nPython (boto3)\\ns3_client = boto3.client('s3') \\n \\n# List all buckets \\ns3_client.list_buckets() \\n \\n# List objects within bucket \\ns3_client.list_objects(Bucket=bucket_name) \\nDelete buckets\\nCLI\\naws s3 rb s3://bucket-name\\nPython (boto3)\\ns3_client = boto3.client('s3') \\ns3_client.delete_bucket(Bucket=bucket_name) \\n\\n\\nDelete objects\\nCLI\\naws s3 rm s3://bucket-name/object-key\\nPython (boto3)\\ns3_client = boto3.client('s3') \\ns3_client.delete_object(Bucket=bucket_name, Key=object_key) \\nCopy objects\\nThe following command can be used to move objects from a bucket or a local directory\\n# Copy from one bucket to another \\naws s3 cp s3://old-bucket/example s3://new-bucket/ \\n \\n# Copy from local directory to bucket \\naws s3 cp /tmp/filename.txt s3://bucket-name\\nPython (boto3)\\ns3_client = boto3.client('s3') \\n \\n# Copy object from one bucket to another \\ns3_client.copy_object( \\n  Bucket=destination_bucket, \\n  CopySource={\\\"Bucket\\\": original_bucket, \\\"Key\\\": object_key\\\"} \\n) \\n \\n# Copy object from local directory to S3 \\ns3_client.upload_file( \\n  Filename=local_file_path,  # /tmp/filename.txt \\n  Bucket=bucket,  # bucket-name \\n  Key=file_key,  # filename.txt \\n)\",\"original_file_name\":\"aws-guide (1).pdf\"},{\"score\":0.6708532,\"file_id\":\"file_94bf098ddc80e7ca\",\"chunk_index\":2,\"chunk_text\":\"Storage class for the object\\nObject size in bytes\\nStorage classes\\nS3 provides multiple storage classes which are designed for diÔ¨Äerent use-cases.\\nStandard\\nIdeal for frequently accessed or performance-critical data\\nMost expensive storage class\\nIntelligent-Tiering\\nAutomatically moves objects between access tiers based on access patterns\\nGood for use-cases when access patterns are ambiguous\\nStandard Infrequent-access\\nIdeal for long-lived and less frequently access data\\nStorage is cheaper than the Standard class but there is a retrieval fee for data access\\nGlacier\\nIdeal for long-term archiving.\\nConÔ¨Ågurable retrieval times (minutes to hours).\\nMore information about Storage classes can be found here.\\nWhen to use it?\\nS3 is a Ô¨Çexible storage service and thus can be used for a variety of use-cases. Some of the\\ncommon use-cases are:\\nStoring static content and serving it directly to end-users: Common examples of this\\nare static webpages, images, videos, static web assets such as CSS or Javascript assets. S3\\ncan also be conÔ¨Ågured with CloudFront (Amazon's CDN) to improve delivery performance\\nfor such content.\\nData Lake: S3 is ideal for storing raw, unstructured data in any format and thus can be\\nused as the storage layer for building a Data Lake\\nLogs, Backups, and snapshots: S3's infrequent access tier makes storing logs, backups,\\nand snapshots a good-Ô¨Åt. Some of the services which integrate with S3 are RDS, EBS, and\\nCloudTrail.\\nExamples\\nSome examples of how to use S3 for various use-cases:\\nHow to create a blog on AWS using S3 in 3 easy steps\\nBuild Your Data Lake on Amazon S3\\nAmazon RDS Snapshot Export to S3\\nGetting Started\\nThe following examples will take us through some of the more common operations for S3.\",\"original_file_name\":\"aws-guide (1).pdf\"}]}"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "QC027Sholey1",
      "metadata": {
        "id": "QC027Sholey1",
        "outputId": "1f88daca-3a2d-411e-cf06-0e16f1f39630",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traversaal Pro: request successful.\n",
            "Generated answer:\n",
            "An S3 bucket in AWS is a storage container that is conceptually similar to a folder in a traditional file-storage system. It is used to store objects, which are the data files along with their metadata. Before you can store any data in Amazon S3, you need to create a bucket. Each S3 bucket has a globally unique name across all AWS accounts, and objects are stored within these buckets using unique identifiers known as keys. For example, if you have an object named \"omgcat.png\" in a bucket called \"adorable-cat-photos,\" the addressable path for that object would be \"s3://adorable-cat-photos/omgcat.png\" [1].\n",
            "\n",
            "Top source reference:\n",
            "  Score: 0.820\n",
            "  File:  aws-guide (1).pdf\n",
            "  Chunk: Amazon Simple Storage Service (S3)\n",
            "What is it?\n",
            "Amazon Simple Storage Service, commonly known as S3, is a fast, scalable, and durable\n",
            "object-storage service. S3 can be used to store and retrieve any ty...\n"
          ]
        }
      ],
      "source": [
        "# Test Traversaal Pro ‚Äî stable AWS question (answer comes from the AWS Guidebook)\n",
        "result = make_prediction(\"What is an S3 bucket in AWS?\")\n",
        "print(\"Generated answer:\")\n",
        "print(result[\"response\"])\n",
        "print(\"\\nTop source reference:\")\n",
        "if result.get(\"references\"):\n",
        "    top_ref = result[\"references\"][0]\n",
        "    print(f\"  Score: {top_ref['score']:.3f}\")\n",
        "    print(f\"  File:  {top_ref['original_file_name']}\")\n",
        "    print(f\"  Chunk: {top_ref['chunk_text'][:200]}...\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "vr6dbehodif",
      "metadata": {
        "id": "vr6dbehodif",
        "outputId": "a97d1703-f136-448a-9b25-f144e80d6f86",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SerpApi: fetching live search results üåê ...\n",
            "[1] AWS live status. Problems and outages for Amazon Web ...\n",
            "    Real-time AWS (Amazon Web Services) status. Is AWS down or suffering an outages? Here you see what is going on.\n",
            "    Source: https://downdetector.com/status/aws-amazon-web-services/\n",
            "\n",
            "[2] Service health - Feb 19, 2026 | AWS Health Dashboard | Global\n",
            "    The following table is a running log of AWS service interruptions for the past 12 months. Choose a status icon to see status updates for ...\n",
            "    Source: https://health.aws.amazon.com/\n",
            "\n",
            "[3] Service health - Feb 19, 2026 | AWS Health Dashboard\n",
            "    View the overall status and health of AWS services using the AWS Health Dashboard.\n",
            "    Source: https://health.aws.amazon.com/health/status?eventID=arn:aws:health:us-east-1::event/MULTIPLE_SERVICES/AWS_MULTIPLE_SERVICES_OPERATIONAL_ISSUE/AWS_MULTIPLE_SERVICES_OPERATIONAL_ISSUE_BA540_514A652BE1A\n",
            "\n",
            "[4] Aws.amazon.com - Is Amazon Web Services Down ...\n",
            "    Aws.amazon.com is UP and reachable by us. Please check and report on local outages below ... The above graph displays service status activity for Aws.amazon.com ...\n",
            "    Source: https://www.isitdownrightnow.com/aws.amazon.com.html\n"
          ]
        }
      ],
      "source": [
        "# Test SerpApi ‚Äî time-sensitive question (live internet search, NOT from documents)\n",
        "live_answer = search_live(\"Are there any AWS outages right now?\")\n",
        "print(live_answer)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "db-RrmtuqFhC",
      "metadata": {
        "id": "db-RrmtuqFhC"
      },
      "source": [
        "### Define SemanticCaching Class\n",
        "\n",
        "In this cell we define `SemanticCaching`‚Äîa lightweight cache with dual-backend routing:\n",
        "\n",
        "1. **Time-sensitive guard** ‚Äî detects temporal keywords and routes to **SerpApi** (live Google search), bypassing the cache entirely.  \n",
        "2. **FAISS lookup** ‚Äî for stable questions, checks if a semantically similar question was already answered. If yes, returns the cached answer instantly.  \n",
        "3. **Traversaal Pro fallback** ‚Äî on a cache miss, queries the **AWS Guidebook RAG** to get a document-grounded answer, then stores it for future hits.  \n",
        "4. **JSON persistence** ‚Äî cache entries (questions, embeddings, answers) are saved to disk so the index survives notebook restarts.  \n",
        "5. **Latency logging** ‚Äî every call reports whether it was a hit, miss, or live search, and how long it took.\n",
        "\n",
        "---\n",
        "\n",
        "### What Should (and Should NOT) Be Semantically Cached?\n",
        "\n",
        "The cache is backed by the **AWS Guidebook** via Traversaal Pro. Since documentation is stable, most AWS concept questions are excellent cache candidates. The exceptions are anything that requires live, up-to-the-minute data.\n",
        "\n",
        "#### ‚úÖ Good to cache ‚Äî stable AWS documentation answers:\n",
        "| Question | Why it's safe to cache |\n",
        "|---|---|\n",
        "| *\"What is an S3 bucket in AWS?\"* | Core concept, always the same |\n",
        "| *\"How does AWS Lambda work?\"* | Stable service behaviour |\n",
        "| *\"What is AWS IAM?\"* | Conceptual definition from docs |\n",
        "| *\"What is the difference between EC2 and ECS?\"* | Architectural comparison |\n",
        "| *\"How does Amazon CloudFront work?\"* | Service explanation |\n",
        "| *\"What is an AWS VPC?\"* | Networking concept |\n",
        "\n",
        "#### ‚ùå Do NOT cache ‚Äî time-sensitive, answers change even for AWS:\n",
        "| Question | Why it must NOT be cached | Backend |\n",
        "|---|---|---|\n",
        "| *\"Are there any AWS outages right now?\"* | Status changes minute to minute | SerpApi |\n",
        "| *\"What are the latest AWS features this week?\"* | New releases announced daily | SerpApi |\n",
        "| *\"What is the current EC2 pricing today?\"* | AWS updates pricing periodically | SerpApi |\n",
        "| *\"Is AWS S3 down right now?\"* | Real-time health check | SerpApi |\n",
        "| *\"What new services did AWS announce this month?\"* | New info every month | SerpApi |\n",
        "\n",
        "The `is_time_sensitive()` method catches these using a keyword list and routes them to SerpApi ‚Äî they never touch the FAISS index."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "yDHhY-OBSEIw",
      "metadata": {
        "id": "yDHhY-OBSEIw"
      },
      "outputs": [],
      "source": [
        "import faiss            # Efficient similarity search over vector embeddings\n",
        "import json             # Read/write cache from a JSON file\n",
        "import numpy as np      # Numerical operations on embeddings\n",
        "from sentence_transformers import SentenceTransformer  # Load Nomic embed model\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM  # (Optional) LLM for answer gen\n",
        "import time             # Measure latency\n",
        "\n",
        "class SemanticCaching:\n",
        "    \"\"\"\n",
        "    A semantic cache that routes queries to the right backend:\n",
        "\n",
        "    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
        "    ‚îÇ  Query                                                   ‚îÇ\n",
        "    ‚îÇ    ‚îÇ                                                     ‚îÇ\n",
        "    ‚îÇ    ‚îú‚îÄ Time-sensitive? ‚îÄ‚îÄYES‚îÄ‚îÄ‚ñ∂ SerpApi (live search)     ‚îÇ\n",
        "    ‚îÇ    ‚îÇ                           NOT cached                ‚îÇ\n",
        "    ‚îÇ    ‚îÇ                                                     ‚îÇ\n",
        "    ‚îÇ    ‚îî‚îÄ Stable? ‚îÄ‚îÄ‚ñ∂ FAISS lookup                          ‚îÇ\n",
        "    ‚îÇ                     ‚îÇ                                    ‚îÇ\n",
        "    ‚îÇ                     ‚îú‚îÄ HIT  ‚îÄ‚îÄ‚ñ∂ return cached answer ‚ö°  ‚îÇ\n",
        "    ‚îÇ                     ‚îÇ                                    ‚îÇ\n",
        "    ‚îÇ                     ‚îî‚îÄ MISS ‚îÄ‚îÄ‚ñ∂ Traversaal Pro (RAG)     ‚îÇ\n",
        "    ‚îÇ                                 store ‚Üí return           ‚îÇ\n",
        "    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
        "    \"\"\"\n",
        "\n",
        "    # Keywords that signal the question is time-sensitive and must NOT be cached.\n",
        "    # Answers to these questions change over time ‚Äî caching would return stale results.\n",
        "    TIME_SENSITIVE_KEYWORDS = [\n",
        "        \"today\", \"tonight\", \"now\", \"currently\", \"current\",\n",
        "        \"latest\", \"recent\", \"recently\", \"right now\", \"at the moment\",\n",
        "        \"at present\", \"as of now\", \"this week\", \"this month\", \"this year\",\n",
        "        \"this quarter\", \"this season\", \"this morning\", \"this afternoon\",\n",
        "        \"this evening\", \"this weekend\", \"yesterday\", \"tomorrow\",\n",
        "        \"last week\", \"last month\", \"last year\", \"upcoming\", \"live\",\n",
        "        \"breaking\", \"just happened\", \"what time\", \"what day\", \"what date\",\n",
        "        \"happening now\", \"events today\", \"news today\", \"news this week\",\n",
        "        \"stock price\", \"share price\", \"weather\", \"forecast\", \"temperature\",\n",
        "        \"real-time\", \"realtime\", \"schedule today\", \"outage\", \"down right now\",\n",
        "        \"is aws down\", \"aws status\",\n",
        "    ]\n",
        "\n",
        "    def __init__(self, json_file='cache.json', clear_on_init=False):\n",
        "        # Initialize Faiss index with Euclidean distance\n",
        "        self.index = faiss.IndexFlatL2(768)\n",
        "        if self.index.is_trained:\n",
        "            print('Index trained')\n",
        "\n",
        "        # Initialize Sentence Transformer model\n",
        "        self.encoder = SentenceTransformer('nomic-ai/nomic-embed-text-v1.5', trust_remote_code=True)\n",
        "\n",
        "        # Euclidean distance threshold for cache hits (lower = stricter)\n",
        "        self.euclidean_threshold = 0.2\n",
        "\n",
        "        # JSON file to persist cache entries\n",
        "        self.json_file = json_file\n",
        "\n",
        "        # Load cache or clear already loaded cache\n",
        "        if clear_on_init:\n",
        "            self.clear_cache()\n",
        "        else:\n",
        "            self.load_cache()\n",
        "\n",
        "    # ------------------------------------------------------------------\n",
        "    # Time-sensitivity detection\n",
        "    # ------------------------------------------------------------------\n",
        "\n",
        "    def is_time_sensitive(self, question: str) -> bool:\n",
        "        \"\"\"\n",
        "        Returns True if the question is time-sensitive and should NOT be cached.\n",
        "\n",
        "        Time-sensitive questions reference current events, live data, or time-bound\n",
        "        information whose answers change frequently. These are routed to SerpApi\n",
        "        for a real-time Google search answer instead of the document RAG system.\n",
        "\n",
        "        Examples that return True (‚Üí SerpApi, never cached):\n",
        "            'Are there any AWS outages right now?'\n",
        "            'What are the latest AWS features released this week?'\n",
        "            'What is the current EC2 pricing today?'\n",
        "            'Is AWS S3 down right now?'\n",
        "\n",
        "        Examples that return False (‚Üí check cache, then Traversaal Pro if miss):\n",
        "            'What is an S3 bucket in AWS?'\n",
        "            'How does AWS Lambda work?'\n",
        "            'What is AWS IAM?'\n",
        "            'What is the difference between EC2 and ECS?'\n",
        "        \"\"\"\n",
        "        question_lower = question.lower()\n",
        "        return any(keyword in question_lower for keyword in self.TIME_SENSITIVE_KEYWORDS)\n",
        "\n",
        "    # ------------------------------------------------------------------\n",
        "    # Cache persistence\n",
        "    # ------------------------------------------------------------------\n",
        "\n",
        "    def clear_cache(self):\n",
        "        \"\"\"Clears in-memory cache, resets FAISS index, and overwrites the JSON file.\"\"\"\n",
        "        self.cache = {\n",
        "            'questions': [],\n",
        "            'embeddings': [],\n",
        "            'answers': [],\n",
        "            'response_text': []\n",
        "        }\n",
        "        self.index = faiss.IndexFlatL2(768)\n",
        "        self.save_cache()\n",
        "        print(\"Semantic cache cleared.\")\n",
        "\n",
        "    def load_cache(self):\n",
        "        \"\"\"Load existing cache or initialize empty structure.\"\"\"\n",
        "        try:\n",
        "            with open(self.json_file, 'r') as file:\n",
        "                self.cache = json.load(file)\n",
        "        except FileNotFoundError:\n",
        "            self.cache = {'questions': [], 'embeddings': [], 'answers': [], 'response_text': []}\n",
        "\n",
        "    def save_cache(self):\n",
        "        \"\"\"Persist cache back to disk.\"\"\"\n",
        "        with open(self.json_file, 'w') as file:\n",
        "            json.dump(self.cache, file)\n",
        "\n",
        "    # ------------------------------------------------------------------\n",
        "    # Main query method\n",
        "    # ------------------------------------------------------------------\n",
        "\n",
        "    def ask(self, question: str) -> str:\n",
        "        \"\"\"\n",
        "        Route the question to the correct backend and return an answer.\n",
        "\n",
        "        Routing logic:\n",
        "          1. Time-sensitive  ‚Üí SerpApi (live Google search) ‚Äî answer NOT cached\n",
        "          2. Cache HIT       ‚Üí return stored answer instantly\n",
        "          3. Cache MISS      ‚Üí Traversaal Pro (RAG over AWS docs) ‚Äî answer stored\n",
        "        \"\"\"\n",
        "        start_time = time.time()\n",
        "\n",
        "        # ‚îÄ‚îÄ 1. Time-sensitivity guard ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "        # Live search via SerpApi ‚Äî result intentionally not stored\n",
        "        if self.is_time_sensitive(question):\n",
        "            print(\"‚è∞ Time-sensitive question ‚Äî routing to SerpApi (live search, not cached).\")\n",
        "            response_text = search_live(question)\n",
        "            print(f\"Time taken: {time.time() - start_time:.3f}s\")\n",
        "            return response_text\n",
        "\n",
        "        try:\n",
        "            # ‚îÄ‚îÄ 2. Cache lookup ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "            embedding = self.encoder.encode([question], normalize_embeddings=True)\n",
        "            D, I = self.index.search(embedding, 1)\n",
        "\n",
        "            if D[0] >= 0:\n",
        "                if I[0][0] != -1 and D[0][0] <= self.euclidean_threshold:\n",
        "                    row_id = int(I[0][0])\n",
        "                    print(f'‚úÖ Cache hit at row: {row_id} | similarity: {1 - D[0][0]:.4f}')\n",
        "                    print(f\"Time taken: {time.time() - start_time:.3f}s\")\n",
        "                    return self.cache['response_text'][row_id]\n",
        "\n",
        "            # ‚îÄ‚îÄ 3. Cache miss ‚Üí Traversaal Pro RAG ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "            answer, response_text = self.generate_answer(question)\n",
        "\n",
        "            self.cache['questions'].append(question)\n",
        "            self.cache['embeddings'].append(embedding[0].tolist())\n",
        "            self.cache['answers'].append(answer)\n",
        "            self.cache['response_text'].append(response_text)\n",
        "            self.index.add(embedding)\n",
        "            self.save_cache()\n",
        "            print(f\"Time taken: {time.time() - start_time:.3f}s\")\n",
        "\n",
        "            return response_text\n",
        "\n",
        "        except Exception as e:\n",
        "            raise RuntimeError(f\"Error during 'ask' method: {e}\")\n",
        "\n",
        "    def generate_answer(self, question: str):\n",
        "        \"\"\"\n",
        "        Call Traversaal Pro to answer a stable document-grounded question.\n",
        "\n",
        "        Uses the AWS Guidebook corpus loaded into your Traversaal Pro project.\n",
        "        Extracts the 'response' field from the API reply as the answer text.\n",
        "\n",
        "        Returns:\n",
        "            tuple: (full API result dict, answer string)\n",
        "        \"\"\"\n",
        "        try:\n",
        "            result = make_prediction(question)\n",
        "            # Traversaal Pro returns {\"response\": \"...\", \"references\": [...]}\n",
        "            response_text = result.get('response', str(result))\n",
        "            return result, response_text\n",
        "        except Exception as e:\n",
        "            raise RuntimeError(f\"Error during 'generate_answer' method: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "dc661dab-f7cc-4d74-9575-1c756b4cdef0",
      "metadata": {
        "id": "dc661dab-f7cc-4d74-9575-1c756b4cdef0",
        "outputId": "a4773204-d150-418b-e4f8-9896709cd6f1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index trained\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:transformers_modules.nomic_hyphen_ai.nomic_hyphen_bert_hyphen_2048.7710840340a098cfb869c4f65e87cf2b1b70caca.modeling_hf_nomic_bert:<All keys matched successfully>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Semantic cache cleared.\n"
          ]
        }
      ],
      "source": [
        "# Instantiate the semantic cache: builds/loads FAISS index, encoder, and JSON cache\n",
        "cache = SemanticCaching()\n",
        "\n",
        "# Uncomment and use to re-instantiate the semantic cache and clear exisitng cache entries\n",
        "#cache = SemanticCaching(clear_on_init=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "noc3G8Abxy2t",
      "metadata": {
        "id": "noc3G8Abxy2t"
      },
      "source": [
        "### Testing the Semantic Cache\n",
        "\n",
        "We validate the `SemanticCaching` class using AWS Guidebook questions. These are stable, document-grounded questions ‚Äî ideal for caching because the answers don't change over time.\n",
        "\n",
        "Watch the routing in action:\n",
        "- **First ask** of a question ‚Üí cache miss ‚Üí Traversaal Pro RAG ‚Üí answer stored  \n",
        "- **Rephrased version** of the same question ‚Üí cache hit ‚Üí instant return  \n",
        "- **Time-sensitive question** ‚Üí SerpApi live search ‚Üí never stored"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "2f64fe4d-fe89-44a7-bf3f-3ad721985f3e",
      "metadata": {
        "id": "2f64fe4d-fe89-44a7-bf3f-3ad721985f3e",
        "outputId": "76495409-e754-4052-d702-edeee99a38c9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traversaal Pro: request successful.\n",
            "Time taken: 7.519s\n",
            "An S3 bucket in AWS is a storage container used to store objects in the Amazon Simple Storage Service (S3). It is conceptually similar to a folder in traditional file-storage systems. Each S3 bucket is globally unique across all AWS accounts, meaning that no two buckets can have the same name. Objects are stored within these buckets, and you must create a bucket before you can store any data in S3. For example, if you have an object named \"omgcat.png\" in a bucket called \"adorable-cat-photos,\" the addressable path for that object would be \"s3://adorable-cat-photos/omgcat.png\" [1].\n",
            "Traversaal Pro: request successful.\n",
            "Time taken: 8.768s\n",
            "AWS Lambda is a serverless computing service that allows developers to run their code in the cloud without managing servers. It operates on an event-driven model where functions are executed in response to specific triggers. Here's how it works:\n",
            "\n",
            "1. **Functions**: Developers write functions that process invocation events. Each function takes two arguments: an event object, which contains details about the event, and a context object, which provides information about the Lambda runtime (such as function name and memory limit).\n",
            "\n",
            "2. **Execution Environment**: AWS Lambda provides a secure and isolated runtime environment where functions are executed. This environment manages the necessary resources to run the functions.\n",
            "\n",
            "3. **Runtimes**: AWS Lambda supports multiple programming languages through the use of runtimes, which are selected when creating a function.\n",
            "\n",
            "4. **Triggers**: Functions are triggered by specific events, which can originate from other AWS services or custom applications. For example, a function can be triggered when a new object is uploaded to Amazon S3.\n",
            "\n",
            "5. **Concurrency**: This refers to the number of requests that a Lambda function can handle simultaneously.\n",
            "\n",
            "6. **Cold Starts**: A cold start occurs when a function is invoked after a period of inactivity, leading to increased latency. Provisioned concurrency can be used to mitigate this issue by keeping functions initialized and ready to respond.\n",
            "\n",
            "7. **Resource Limits**: AWS Lambda has certain limits, such as a maximum execution time of 15 minutes, a maximum memory allocation of 3008 MB, and a maximum deployment package size of 50 MB.\n",
            "\n",
            "AWS Lambda is particularly suitable for use cases like chatbots, image or video processing, serverless websites, and ETL jobs [1].\n",
            "Traversaal Pro: request successful.\n",
            "Time taken: 6.059s\n",
            "The provided context does not include any information about AWS IAM (Identity and Access Management) or its uses. Therefore, I cannot answer your query based on the given context. If you need information about AWS IAM, please refer to additional resources or documentation.\n",
            "Traversaal Pro: request successful.\n",
            "Time taken: 6.403s\n",
            "The context provided does not contain specific information about Amazon VPC. Therefore, I am unable to answer your query based on the given context. If you have any other questions or need information on a different topic, feel free to ask!\n"
          ]
        }
      ],
      "source": [
        "# Q1: Cache miss ‚Äî Traversaal Pro answers from AWS docs, stores result\n",
        "question1 = \"What is an S3 bucket in AWS?\"\n",
        "answer1 = cache.ask(question1)\n",
        "print(answer1)\n",
        "\n",
        "# Q2: Cache miss ‚Äî different AWS service\n",
        "question2 = \"How does AWS Lambda work?\"\n",
        "answer2 = cache.ask(question2)\n",
        "print(answer2)\n",
        "\n",
        "\n",
        "# Note:\n",
        "# All two are distinct enough to each get a separate Traversaal Pro call.\n",
        "# Next, we'll test cache hits with rephrased versions of these questions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "5eade92a-a4f7-406f-85d3-ae24146d9c00",
      "metadata": {
        "id": "5eade92a-a4f7-406f-85d3-ae24146d9c00",
        "outputId": "ef3a18c9-a93a-4f52-9767-6f99889a0dc2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traversaal Pro: request successful.\n",
            "Time taken: 7.485s\n",
            "Amazon S3 buckets are a fundamental concept within the Amazon Simple Storage Service (S3), which is an object-storage service designed for storing and retrieving any type and amount of data. A bucket in S3 is similar to a folder in a traditional file-storage system, where objects (data) are stored. Each S3 bucket must be created before any data can be stored in S3.\n",
            "\n",
            "Buckets are globally unique across all AWS accounts, meaning that no two buckets can have the same name. For example, if a bucket named \"adorable-cat-photos\" already exists, no one else can create a bucket with that name. Additionally, access control can be implemented at the bucket level, and AWS billing is based on the aggregate sizes of the buckets created [1]. \n",
            "\n",
            "To summarize, an S3 bucket serves as a container for storing objects, and understanding buckets is crucial for managing data in Amazon S3 effectively [1].\n"
          ]
        }
      ],
      "source": [
        "# Cache HIT ‚Äî rephrased version of Q1 (\"What is an S3 bucket?\")\n",
        "# The FAISS index finds the stored embedding is similar enough ‚Üí returns instantly\n",
        "print(cache.ask(\"Can you explain what Amazon S3 buckets are?\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "7b9a6a23-83d7-4688-b037-fc015f295e83",
      "metadata": {
        "collapsed": true,
        "id": "7b9a6a23-83d7-4688-b037-fc015f295e83",
        "outputId": "f5f9dbb7-d3fa-4c16-e850-9253a5ba9ffb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traversaal Pro: request successful.\n",
            "Time taken: 6.203s\n",
            "The provided context does not include information about Amazon CloudFront. Therefore, I cannot answer your query regarding what Amazon CloudFront is and how it works based on the given context. If you have further questions or need information on other AWS services mentioned, feel free to ask!\n"
          ]
        }
      ],
      "source": [
        "# Cache MISS ‚Äî new AWS concept not yet in cache ‚Üí Traversaal Pro call\n",
        "print(cache.ask(\"What is Amazon CloudFront and how does it work?\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2P3Tso8TTElH",
      "metadata": {
        "collapsed": true,
        "id": "2P3Tso8TTElH"
      },
      "outputs": [],
      "source": [
        "# Cache HIT ‚Äî semantically similar to the CloudFront question above\n",
        "print(cache.ask(\"How does AWS CloudFront serve content to users?\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "015dd13f-9de9-409b-9273-6730fe173585",
      "metadata": {
        "collapsed": true,
        "id": "015dd13f-9de9-409b-9273-6730fe173585"
      },
      "outputs": [],
      "source": [
        "# Cache MISS ‚Äî new question about DynamoDB ‚Üí Traversaal Pro call + stored\n",
        "print(cache.ask(\"What is Amazon DynamoDB and when should I use it?\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2cf696d0-2660-4cae-99b1-583807e7e5f1",
      "metadata": {
        "collapsed": true,
        "id": "2cf696d0-2660-4cae-99b1-583807e7e5f1"
      },
      "outputs": [],
      "source": [
        "# Cache HIT ‚Äî rephrased DynamoDB question ‚Üí returned from cache instantly\n",
        "print(cache.ask(\"When would I choose DynamoDB over other databases on AWS?\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b4e94626-1fd1-4493-8b8f-9550a1460e7a",
      "metadata": {
        "collapsed": true,
        "id": "b4e94626-1fd1-4493-8b8f-9550a1460e7a"
      },
      "outputs": [],
      "source": [
        "# Cache MISS ‚Äî different enough to not match DynamoDB ‚Üí Traversaal Pro call\n",
        "print(cache.ask(\"How does Amazon RDS differ from DynamoDB?\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5ys1zxjtkc4",
      "metadata": {
        "id": "5ys1zxjtkc4"
      },
      "source": [
        "### Testing the Time-Sensitivity Filter + Dual-Backend Routing\n",
        "\n",
        "Here we demonstrate the full routing logic:\n",
        "\n",
        "| Question type | Detected by | Backend | Cached? |\n",
        "|---|---|---|---|\n",
        "| Contains temporal keyword | `is_time_sensitive()` ‚Üí `True` | **SerpApi** (live Google search) | ‚ùå Never |\n",
        "| Stable AWS concept | `is_time_sensitive()` ‚Üí `False` + cache miss | **Traversaal Pro** (AWS docs RAG) | ‚úÖ Stored |\n",
        "| Previously seen question | `is_time_sensitive()` ‚Üí `False` + cache hit | **FAISS cache** | ‚úÖ Already stored |\n",
        "\n",
        "**AWS-specific time-sensitive examples** ‚Äî even though they're about AWS, these need live answers:\n",
        "- *\"Are there any AWS outages right now?\"* ‚Üí changes minute to minute  \n",
        "- *\"What are the latest AWS features released this week?\"* ‚Üí new announcements daily  \n",
        "- *\"What is the current EC2 pricing today?\"* ‚Üí pricing can be updated by AWS anytime  \n",
        "\n",
        "**AWS stable examples** ‚Äî these come from documentation and don't change:\n",
        "- *\"What is an S3 bucket?\"* ‚Äî always the same concept\n",
        "- *\"How does Lambda work?\"* ‚Äî core service behaviour is stable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dlfbvrouhim",
      "metadata": {
        "id": "dlfbvrouhim"
      },
      "outputs": [],
      "source": [
        "# Classification check ‚Äî see which questions are flagged before running any queries\n",
        "time_sensitive_aws = [\n",
        "    \"Are there any AWS outages right now?\",\n",
        "    \"What are the latest AWS features released this week?\",\n",
        "    \"What is the current EC2 pricing today?\",\n",
        "    \"Is AWS S3 down right now?\",\n",
        "    \"What new services did AWS announce this month?\",\n",
        "    \"What is the current AWS free tier limit as of now?\",\n",
        "]\n",
        "\n",
        "stable_aws = [\n",
        "    \"What is an S3 bucket in AWS?\",\n",
        "    \"How does AWS Lambda work?\",\n",
        "    \"What is AWS IAM?\",\n",
        "    \"What is the difference between EC2 and ECS?\",\n",
        "    \"How does Amazon CloudFront work?\",\n",
        "    \"What is an AWS VPC?\",\n",
        "]\n",
        "\n",
        "print(\"=== Time-Sensitive AWS Questions (‚Üí SerpApi, never cached) ===\")\n",
        "for q in time_sensitive_aws:\n",
        "    flag = cache.is_time_sensitive(q)\n",
        "    label = \"‚è∞ SerpApi (live)\" if flag else \"‚úÖ Traversaal Pro (cached)\"\n",
        "    print(f\"  [{label}] {q}\")\n",
        "\n",
        "print(\"\\n=== Stable AWS Questions (‚Üí Traversaal Pro on miss, cached) ===\")\n",
        "for q in stable_aws:\n",
        "    flag = cache.is_time_sensitive(q)\n",
        "    label = \"‚è∞ SerpApi (live)\" if flag else \"‚úÖ Traversaal Pro (cached)\"\n",
        "    print(f\"  [{label}] {q}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "xm8an2uz38",
      "metadata": {
        "id": "xm8an2uz38"
      },
      "outputs": [],
      "source": [
        "# Time-sensitive AWS questions ‚Üí routed to SerpApi, NEVER stored in cache\n",
        "# Ask the same question twice ‚Äî both calls go live, nothing accumulates in FAISS\n",
        "\n",
        "print(\"--- Query A (time-sensitive: outage check) ---\")\n",
        "print(cache.ask(\"Are there any AWS outages right now?\"))\n",
        "\n",
        "print(\"\\n--- Query A again (still time-sensitive ‚Üí SerpApi again, not cached) ---\")\n",
        "print(cache.ask(\"Are there any AWS outages right now?\"))\n",
        "\n",
        "print(\"\\n--- Query B (time-sensitive: pricing) ---\")\n",
        "print(cache.ask(\"What is the current EC2 pricing today?\"))\n",
        "\n",
        "# Verify the cache count has not grown due to these time-sensitive calls\n",
        "print(f\"\\nCache entries (should be same as before): {len(cache.cache['questions'])}\")\n",
        "print(\"Cached questions:\", cache.cache['questions'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "w7nq7un0l6j",
      "metadata": {
        "id": "w7nq7un0l6j"
      },
      "outputs": [],
      "source": [
        "# Stable AWS question ‚Üí cache miss on first call (Traversaal Pro), cache hit on second\n",
        "print(\"--- Query C (stable AWS, first call ‚Üí Traversaal Pro) ---\")\n",
        "print(cache.ask(\"How do you configure S3 bucket policies?\"))\n",
        "\n",
        "print(\"\\n--- Query D (semantically similar to C ‚Üí cache hit) ---\")\n",
        "print(cache.ask(\"What is the way to set up an S3 bucket access policy?\"))\n",
        "\n",
        "print(f\"\\nTotal cached entries now: {len(cache.cache['questions'])}\")\n",
        "print(\"Cached questions:\", cache.cache['questions'])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "olive-python",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.14.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}